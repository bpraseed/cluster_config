{
  "roleTypeConfigs" : [ {
    "roleType" : "KAFKA_BROKER",
    "items" : [ {
      "name" : "broker_max_heap_size",
      "value" : "1024",
      "required" : false,
      "default" : "256",
      "displayName" : "Java Heap Size of Broker in Megabytes",
      "description" : "Maximum size for the Java process heap memory. Passed to Java -Xmx. Measured in megabytes.",
      "relatedName" : "broker_max_heap_size",
      "validationState" : "OK"
    }, {
      "name" : "log.retention.hours",
      "value" : "1",
      "required" : false,
      "default" : "168",
      "displayName" : "Data Retention Time",
      "description" : "The number of hours to keep a log segment before it is deleted, i.e. the default data retention window for all topics. Note that if both log.retention.hours and log.retention.bytes are both set, segments are deleted when either limit is exceeded.",
      "relatedName" : "log.retention.hours",
      "validationState" : "OK"
    }, {
      "name" : "port",
      "required" : false,
      "default" : "9092",
      "displayName" : "TCP Port",
      "description" : "Kafka broker port.",
      "relatedName" : "port",
      "validationState" : "OK"
    }, {
      "name" : "kafka_broker_fd_thresholds",
      "required" : false,
      "default" : "{\"critical\":\"70.0\",\"warning\":\"50.0\"}",
      "displayName" : "File Descriptor Monitoring Thresholds",
      "description" : "The health test thresholds of the number of file descriptors used. Specified as a percentage of file descriptor limit.",
      "relatedName" : "",
      "validationState" : "OK"
    }, {
      "name" : "log.roll.hours",
      "required" : false,
      "default" : "168",
      "displayName" : "Time Based Roll",
      "description" : "Time in hours to roll a new segment file. This setting will force Kafka to roll a new log segment even if the log.segment.bytes size has not been reached.",
      "relatedName" : "log.roll.hours",
      "validationState" : "OK"
    }, {
      "name" : "kafka_broker_scm_health_enabled",
      "required" : false,
      "default" : "true",
      "displayName" : "Kafka Broker Process Health Test",
      "description" : "Enables the health test that the Kafka Broker's process state is consistent with the role configuration",
      "relatedName" : "",
      "validationState" : "OK"
    }, {
      "name" : "log.segment.bytes",
      "required" : false,
      "default" : "106954752",
      "displayName" : "Segment File Size",
      "description" : "The log for a topic partition is stored as a directory of segment files. This setting controls the size to which a segment file will grow before a new segment is rolled over in the log.",
      "relatedName" : "log.segment.bytes",
      "validationState" : "OK"
    }, {
      "name" : "advertised.host.name",
      "required" : false,
      "displayName" : "Advertised Host",
      "description" : "If this is set this is the hostname that will be given out to producers, consumers, and other brokers to connect to. Never set this property on service level, it should always be overriden on instance level.",
      "relatedName" : "advertised.host.name",
      "validationState" : "OK"
    }, {
      "name" : "log_threshold",
      "required" : false,
      "default" : "INFO",
      "displayName" : "Kafka Broker Logging Threshold",
      "description" : "The minimum log level for Kafka Broker logs",
      "relatedName" : "",
      "validationState" : "OK"
    }, {
      "name" : "kafka.http.metrics.host",
      "required" : false,
      "default" : "0.0.0.0",
      "displayName" : "HTTP Metric Report Host",
      "description" : "Host the HTTP metric reporter will bind to.",
      "relatedName" : "kafka.http.metrics.host",
      "validationState" : "OK"
    }, {
      "name" : "kafka_broker_host_health_enabled",
      "required" : false,
      "default" : "true",
      "displayName" : "Kafka Broker Host Health Test",
      "description" : "When computing the overall Kafka Broker health, consider the host's health.",
      "relatedName" : "",
      "validationState" : "OK"
    }, {
      "name" : "kafka.http.metrics.port",
      "required" : false,
      "default" : "24042",
      "displayName" : "HTTP Metric Report Port",
      "description" : "Port the HTTP metric reporter will listen on.",
      "relatedName" : "kafka.http.metrics.port",
      "validationState" : "OK"
    }, {
      "name" : "enable_alerts",
      "required" : false,
      "default" : "true",
      "displayName" : "Enable Health Alerts for this Role",
      "description" : "When set, Cloudera Manager will send alerts when the health of this role reaches the threshold specified by the EventServer setting eventserver_health_events_alert_threshold",
      "relatedName" : "",
      "validationState" : "OK"
    }, {
      "name" : "rm_memory_hard_limit",
      "required" : false,
      "default" : "-1",
      "displayName" : "Cgroup Memory Hard Limit",
      "description" : "Hard memory limit to assign to this role, enforced by the Linux kernel. When the limit is reached, the kernel will reclaim pages charged to the process. If reclaiming fails, the kernel may kill the process. Both anonymous as well as page cache pages contribute to the limit. Use a value of -1 B to specify no limit. By default processes not managed by Cloudera Manager will have no limit.",
      "relatedName" : "memory.limit_in_bytes",
      "validationState" : "OK"
    }, {
      "name" : "rm_memory_soft_limit",
      "required" : false,
      "default" : "-1",
      "displayName" : "Cgroup Memory Soft Limit",
      "description" : "Soft memory limit to assign to this role, enforced by the Linux kernel. When the limit is reached, the kernel will reclaim pages charged to the process if and only if the host is facing memory pressure. If reclaiming fails, the kernel may kill the process. Both anonymous as well as page cache pages contribute to the limit. Use a value of -1 B to specify no limit. By default processes not managed by Cloudera Manager will have no limit.",
      "relatedName" : "memory.soft_limit_in_bytes",
      "validationState" : "OK"
    }, {
      "name" : "broker.id",
      "required" : false,
      "displayName" : "Broker ID",
      "description" : "ID uniquely identifying each broker. Never set this property on service level, it should always be overriden on instance level.",
      "relatedName" : "broker.id",
      "validationState" : "OK"
    }, {
      "name" : "process_auto_restart",
      "required" : false,
      "default" : "false",
      "displayName" : "Automatically Restart Process",
      "description" : "When set, this role's process is automatically (and transparently) restarted in the event of an unexpected failure.",
      "relatedName" : "",
      "validationState" : "OK"
    }, {
      "name" : "rm_cpu_shares",
      "required" : false,
      "default" : "1024",
      "displayName" : "Cgroup CPU Shares",
      "description" : "Number of CPU shares to assign to this role. The greater the number of shares, the larger the share of the host's CPUs that will be given to this role when the host experiences CPU contention. Must be between 2 and 262144. Defaults to 1024 for processes not managed by Cloudera Manager.",
      "relatedName" : "cpu.shares",
      "validationState" : "OK"
    }, {
      "name" : "kafka.properties_role_safety_valve",
      "required" : false,
      "displayName" : "Kafka Broker Advanced Configuration Snippet (Safety Valve) for kafka.properties",
      "description" : "For advanced use only, a string to be inserted into <strong>kafka.properties</strong> for this role only.",
      "relatedName" : "",
      "validationState" : "OK"
    }, {
      "name" : "log_dir",
      "required" : false,
      "default" : "/var/log/kafka",
      "displayName" : "Kafka Broker Log Directory",
      "description" : "The log directory for log files of the role Kafka Broker.",
      "relatedName" : "kafka.log4j.dir",
      "validationState" : "OK"
    }, {
      "name" : "rm_io_weight",
      "required" : false,
      "default" : "500",
      "displayName" : "Cgroup I/O Weight",
      "description" : "Weight for the read I/O requests issued by this role. The greater the weight, the higher the priority of the requests when the host experiences I/O contention. Must be between 100 and 1000. Defaults to 1000 for processes not managed by Cloudera Manager.",
      "relatedName" : "blkio.weight",
      "validationState" : "OK"
    }, {
      "name" : "jmx_port",
      "required" : false,
      "default" : "9393",
      "displayName" : "JMX Port",
      "description" : "Port for JMX.",
      "relatedName" : "jmx_port",
      "validationState" : "OK"
    }, {
      "name" : "kafka-monitoring.properties_role_safety_valve",
      "required" : false,
      "displayName" : "Kafka Broker Advanced Configuration Snippet (Safety Valve) for kafka-monitoring.properties",
      "description" : "For advanced use only, a string to be inserted into <strong>kafka-monitoring.properties</strong> for this role only.",
      "relatedName" : "",
      "validationState" : "OK"
    }, {
      "name" : "rlimit_fds",
      "required" : false,
      "displayName" : "Maximum Process File Descriptors",
      "description" : "If configured, overrides the process soft and hard rlimits (also called ulimits) for file descriptors to the configured value.",
      "relatedName" : "",
      "validationState" : "OK"
    }, {
      "name" : "log4j_safety_valve",
      "required" : false,
      "displayName" : "Kafka Broker Logging Advanced Configuration Snippet (Safety Valve)",
      "description" : "For advanced use only, a string to be inserted into <strong>log4j.properties</strong> for this role only.",
      "relatedName" : "",
      "validationState" : "OK"
    }, {
      "name" : "max_log_size",
      "required" : false,
      "default" : "200",
      "displayName" : "Kafka Broker Max Log Size",
      "description" : "The maximum size, in megabytes, per log file for Kafka Broker logs.  Typically used by log4j or logback.",
      "relatedName" : "",
      "validationState" : "OK"
    }, {
      "name" : "unexpected_exits_thresholds",
      "required" : false,
      "default" : "{\"critical\":\"any\",\"warning\":\"never\"}",
      "displayName" : "Unexpected Exits Thresholds",
      "description" : "The health test thresholds for unexpected exits encountered within a recent period specified by the unexpected_exits_window configuration for the role.",
      "relatedName" : "",
      "validationState" : "OK"
    }, {
      "name" : "log.dirs",
      "required" : false,
      "default" : "/var/local/kafka/data",
      "displayName" : "Data Directory",
      "description" : "A comma-separated list of one or more directories in which Kafka data is stored. Each new partition that is created will be placed in the directory which currently has the fewest partitions. Each directory should be on it's own separate drive.",
      "relatedName" : "log.dirs",
      "validationState" : "OK"
    }, {
      "name" : "KAFKA_BROKER_role_env_safety_valve",
      "required" : false,
      "displayName" : "Kafka Broker Environment Advanced Configuration Snippet (Safety Valve)",
      "description" : "For advanced use only, key-value pairs (one on each line) to be inserted into a role's environment. Applies to configurations of this role except client configuration.",
      "relatedName" : "",
      "validationState" : "OK"
    }, {
      "name" : "enable_config_alerts",
      "required" : false,
      "default" : "false",
      "displayName" : "Enable Configuration Change Alerts",
      "description" : "When set, Cloudera Manager will send alerts when this entity's configuration changes.",
      "relatedName" : "",
      "validationState" : "OK"
    }, {
      "name" : "role_triggers",
      "required" : false,
      "default" : "[]",
      "displayName" : "Role Triggers",
      "description" : "<p>The configured triggers for this role. This is a JSON formatted list of triggers. These triggers are evaluated as part as the health system. Every trigger expression is parsed, and if the trigger condition is met, the list of actions provided in the trigger expression is executed.</p><p>Each trigger has all of the following fields:</p><ul><li><code>triggerName</code> <strong>(mandatory)</strong> - The name of the trigger. This value must be unique for the specific role. </li><li><code>triggerExpression</code> <strong>(mandatory)</strong> - A tsquery expression representing the trigger. </li><li><code>streamThreshold</code> <strong>(optional)</strong> - The maximum number of streams that can satisfy a condition of a trigger before the condition fires. By default set to 0, and any stream returned causes the condition to fire. </li><li><code>enabled</code> <strong> (optional)</strong> - By default set to 'true'. If set to 'false', the trigger will not be evaluated.</li><li><code>expressionEditorConfig</code> <strong> (optional)</strong> - Metadata for the trigger editor. If present, the trigger should only be edited from the Edit Trigger page; editing the trigger here may lead to inconsistencies.</li></ul></p><p>For example, the following JSON formatted trigger configured for a DataNode fires if the DataNode has more than 1500 file-descriptors opened:</p><p><pre>[{\"triggerName\": \"sample-trigger\",\n  \"triggerExpression\": \"IF (SELECT fd_open WHERE roleName=$ROLENAME and last(fd_open) > 1500) DO health:bad\",\n  \"streamThreshold\": 0, \"enabled\": \"true\"}]</pre></p><p>See the trigger rules documentation for more details on how to write triggers using tsquery.</p><p>The JSON format is evolving and may change in the future and, as a result, backward compatibility is not guaranteed between releases at this time.</p>",
      "relatedName" : "",
      "validationState" : "OK"
    }, {
      "name" : "process_swap_memory_thresholds",
      "required" : false,
      "default" : "{\"critical\":\"never\",\"warning\":\"any\"}",
      "displayName" : "Process Swap Memory Thresholds",
      "description" : "The health test thresholds on the swap memory usage of the process.",
      "relatedName" : "",
      "validationState" : "OK"
    }, {
      "name" : "max.connections.per.ip",
      "required" : false,
      "default" : "10",
      "displayName" : "Maximum Connections per IP Address",
      "description" : "Maximum number of connections allowed from each ip address.",
      "relatedName" : "max.connections.per.ip",
      "validationState" : "OK"
    }, {
      "name" : "log.retention.bytes",
      "required" : false,
      "default" : "-1",
      "displayName" : "Data Retention Size",
      "description" : "The amount of data to retain in the log for each topic-partitions. Note that this is the limit per-partition so multiply by the number of partitions to get the total data retained for the topic. Also note that if both log.retention.hours and log.retention.bytes are both set, segments will be deleted when either limit is exceeded.",
      "relatedName" : "log.retention.bytes",
      "validationState" : "OK"
    }, {
      "name" : "max_log_backup_index",
      "required" : false,
      "default" : "10",
      "displayName" : "Kafka Broker Maximum Log File Backups",
      "description" : "The maximum number of rolled log files to keep for Kafka Broker logs.  Typically used by log4j or logback.",
      "relatedName" : "",
      "validationState" : "OK"
    }, {
      "name" : "advertised.port",
      "required" : false,
      "displayName" : "Advertised Port",
      "description" : "The port to give out to producers, consumers, and other brokers to use in establishing connections. This only needs to be set if this port is different from the port the server should bind to. Never set this property on service level, it should always be overriden on instance level.",
      "relatedName" : "advertised.port",
      "validationState" : "OK"
    }, {
      "name" : "unexpected_exits_window",
      "required" : false,
      "default" : "5",
      "displayName" : "Unexpected Exits Monitoring Period",
      "description" : "The period to review when computing unexpected exits.",
      "relatedName" : "",
      "validationState" : "OK"
    } ]
  }, {
    "roleType" : "KAFKA_MIRROR_MAKER",
    "items" : [ {
      "name" : "num.streams",
      "required" : false,
      "default" : "1",
      "displayName" : "Number of Consumer Threads",
      "description" : "Number of consumer threads.",
      "relatedName" : "num.streams",
      "validationState" : "OK"
    }, {
      "name" : "mirror_maker_consumers.properties_role_safety_valve",
      "required" : false,
      "displayName" : "Kafka MirrorMaker Advanced Configuration Snippet (Safety Valve) for mirror_maker_consumers.properties",
      "description" : "For advanced use only, a string to be inserted into <strong>mirror_maker_consumers.properties</strong> for this role only.",
      "relatedName" : "",
      "validationState" : "OK"
    }, {
      "name" : "log_threshold",
      "required" : false,
      "default" : "INFO",
      "displayName" : "Kafka MirrorMaker Logging Threshold",
      "description" : "The minimum log level for Kafka MirrorMaker logs",
      "relatedName" : "",
      "validationState" : "OK"
    }, {
      "name" : "mirror_maker_producers.properties_role_safety_valve",
      "required" : false,
      "displayName" : "Kafka MirrorMaker Advanced Configuration Snippet (Safety Valve) for mirror_maker_producers.properties",
      "description" : "For advanced use only, a string to be inserted into <strong>mirror_maker_producers.properties</strong> for this role only.",
      "relatedName" : "",
      "validationState" : "OK"
    }, {
      "name" : "kafka_mirror_maker_fd_thresholds",
      "required" : false,
      "default" : "{\"critical\":\"70.0\",\"warning\":\"50.0\"}",
      "displayName" : "File Descriptor Monitoring Thresholds",
      "description" : "The health test thresholds of the number of file descriptors used. Specified as a percentage of file descriptor limit.",
      "relatedName" : "",
      "validationState" : "OK"
    }, {
      "name" : "bootstrap.servers",
      "required" : false,
      "displayName" : "Destination Broker List",
      "description" : "List of brokers on destination cluster. This should be more than one, for high availability, but there's no need to list all brokers.",
      "relatedName" : "bootstrap.servers",
      "validationState" : "OK"
    }, {
      "name" : "enable_alerts",
      "required" : false,
      "default" : "true",
      "displayName" : "Enable Health Alerts for this Role",
      "description" : "When set, Cloudera Manager will send alerts when the health of this role reaches the threshold specified by the EventServer setting eventserver_health_events_alert_threshold",
      "relatedName" : "",
      "validationState" : "OK"
    }, {
      "name" : "kafka_mirror_maker_scm_health_enabled",
      "required" : false,
      "default" : "true",
      "displayName" : "Kafka MirrorMaker Process Health Test",
      "description" : "Enables the health test that the Kafka MirrorMaker's process state is consistent with the role configuration",
      "relatedName" : "",
      "validationState" : "OK"
    }, {
      "name" : "rm_memory_hard_limit",
      "required" : false,
      "default" : "-1",
      "displayName" : "Cgroup Memory Hard Limit",
      "description" : "Hard memory limit to assign to this role, enforced by the Linux kernel. When the limit is reached, the kernel will reclaim pages charged to the process. If reclaiming fails, the kernel may kill the process. Both anonymous as well as page cache pages contribute to the limit. Use a value of -1 B to specify no limit. By default processes not managed by Cloudera Manager will have no limit.",
      "relatedName" : "memory.limit_in_bytes",
      "validationState" : "OK"
    }, {
      "name" : "KAFKA_MIRROR_MAKER_role_env_safety_valve",
      "required" : false,
      "displayName" : "Kafka MirrorMaker Environment Advanced Configuration Snippet (Safety Valve)",
      "description" : "For advanced use only, key-value pairs (one on each line) to be inserted into a role's environment. Applies to configurations of this role except client configuration.",
      "relatedName" : "",
      "validationState" : "OK"
    }, {
      "name" : "rm_memory_soft_limit",
      "required" : false,
      "default" : "-1",
      "displayName" : "Cgroup Memory Soft Limit",
      "description" : "Soft memory limit to assign to this role, enforced by the Linux kernel. When the limit is reached, the kernel will reclaim pages charged to the process if and only if the host is facing memory pressure. If reclaiming fails, the kernel may kill the process. Both anonymous as well as page cache pages contribute to the limit. Use a value of -1 B to specify no limit. By default processes not managed by Cloudera Manager will have no limit.",
      "relatedName" : "memory.soft_limit_in_bytes",
      "validationState" : "OK"
    }, {
      "name" : "process_auto_restart",
      "required" : false,
      "default" : "false",
      "displayName" : "Automatically Restart Process",
      "description" : "When set, this role's process is automatically (and transparently) restarted in the event of an unexpected failure.",
      "relatedName" : "",
      "validationState" : "OK"
    }, {
      "name" : "rm_cpu_shares",
      "required" : false,
      "default" : "1024",
      "displayName" : "Cgroup CPU Shares",
      "description" : "Number of CPU shares to assign to this role. The greater the number of shares, the larger the share of the host's CPUs that will be given to this role when the host experiences CPU contention. Must be between 2 and 262144. Defaults to 1024 for processes not managed by Cloudera Manager.",
      "relatedName" : "cpu.shares",
      "validationState" : "OK"
    }, {
      "name" : "whitelist",
      "required" : false,
      "default" : "",
      "displayName" : "Topic Whitelist",
      "description" : "Regular expression that represent a set of topics to mirror. Note that whitelist and blacklist parameters are mutually exclusive. If both are defined, only the whilelist is used.",
      "relatedName" : "whitelist",
      "validationState" : "OK"
    }, {
      "name" : "kafka_mirror_maker_host_health_enabled",
      "required" : false,
      "default" : "true",
      "displayName" : "Kafka MirrorMaker Host Health Test",
      "description" : "When computing the overall Kafka MirrorMaker health, consider the host's health.",
      "relatedName" : "",
      "validationState" : "OK"
    }, {
      "name" : "log_dir",
      "required" : false,
      "default" : "/var/log/kafka",
      "displayName" : "Kafka MirrorMaker Log Directory",
      "description" : "The log directory for log files of the role Kafka MirrorMaker.",
      "relatedName" : "kafka_mirrormaker.log4j.dir",
      "validationState" : "OK"
    }, {
      "name" : "rm_io_weight",
      "required" : false,
      "default" : "500",
      "displayName" : "Cgroup I/O Weight",
      "description" : "Weight for the read I/O requests issued by this role. The greater the weight, the higher the priority of the requests when the host experiences I/O contention. Must be between 100 and 1000. Defaults to 1000 for processes not managed by Cloudera Manager.",
      "relatedName" : "blkio.weight",
      "validationState" : "OK"
    }, {
      "name" : "no.data.loss",
      "required" : false,
      "default" : "true",
      "displayName" : "Avoid Data Loss",
      "description" : "Run with MirrorMaker settings that eliminate potential loss of data. This impacts performance but is highly recommended.",
      "relatedName" : "no.data.loss",
      "validationState" : "OK"
    }, {
      "name" : "jmx_port",
      "required" : false,
      "default" : "9394",
      "displayName" : "JMX Port",
      "description" : "Port for JMX.",
      "relatedName" : "jmx_port",
      "validationState" : "OK"
    }, {
      "name" : "rlimit_fds",
      "required" : false,
      "displayName" : "Maximum Process File Descriptors",
      "description" : "If configured, overrides the process soft and hard rlimits (also called ulimits) for file descriptors to the configured value.",
      "relatedName" : "",
      "validationState" : "OK"
    }, {
      "name" : "log4j_safety_valve",
      "required" : false,
      "displayName" : "Kafka MirrorMaker Logging Advanced Configuration Snippet (Safety Valve)",
      "description" : "For advanced use only, a string to be inserted into <strong>log4j.properties</strong> for this role only.",
      "relatedName" : "",
      "validationState" : "OK"
    }, {
      "name" : "max_log_size",
      "required" : false,
      "default" : "200",
      "displayName" : "Kafka MirrorMaker Max Log Size",
      "description" : "The maximum size, in megabytes, per log file for Kafka MirrorMaker logs.  Typically used by log4j or logback.",
      "relatedName" : "",
      "validationState" : "OK"
    }, {
      "name" : "unexpected_exits_thresholds",
      "required" : false,
      "default" : "{\"critical\":\"any\",\"warning\":\"never\"}",
      "displayName" : "Unexpected Exits Thresholds",
      "description" : "The health test thresholds for unexpected exits encountered within a recent period specified by the unexpected_exits_window configuration for the role.",
      "relatedName" : "",
      "validationState" : "OK"
    }, {
      "name" : "enable_config_alerts",
      "required" : false,
      "default" : "false",
      "displayName" : "Enable Configuration Change Alerts",
      "description" : "When set, Cloudera Manager will send alerts when this entity's configuration changes.",
      "relatedName" : "",
      "validationState" : "OK"
    }, {
      "name" : "group.id",
      "required" : false,
      "default" : "cloudera_mirrormaker",
      "displayName" : "Consumer Group ID",
      "description" : "Name of the consumer group used by MirrorMaker.\n When multiple role instances are configured with the same topics and same group ID, the role instances will load-balance replication for the topics. \n When multiple role instances are configured with with the same topics but different group ID, each role instance will replicate all the events for those topics - this can be used to replicate the source cluster into multiple destination clusters.",
      "relatedName" : "group.id",
      "validationState" : "OK"
    }, {
      "name" : "role_triggers",
      "required" : false,
      "default" : "[]",
      "displayName" : "Role Triggers",
      "description" : "<p>The configured triggers for this role. This is a JSON formatted list of triggers. These triggers are evaluated as part as the health system. Every trigger expression is parsed, and if the trigger condition is met, the list of actions provided in the trigger expression is executed.</p><p>Each trigger has all of the following fields:</p><ul><li><code>triggerName</code> <strong>(mandatory)</strong> - The name of the trigger. This value must be unique for the specific role. </li><li><code>triggerExpression</code> <strong>(mandatory)</strong> - A tsquery expression representing the trigger. </li><li><code>streamThreshold</code> <strong>(optional)</strong> - The maximum number of streams that can satisfy a condition of a trigger before the condition fires. By default set to 0, and any stream returned causes the condition to fire. </li><li><code>enabled</code> <strong> (optional)</strong> - By default set to 'true'. If set to 'false', the trigger will not be evaluated.</li><li><code>expressionEditorConfig</code> <strong> (optional)</strong> - Metadata for the trigger editor. If present, the trigger should only be edited from the Edit Trigger page; editing the trigger here may lead to inconsistencies.</li></ul></p><p>For example, the following JSON formatted trigger configured for a DataNode fires if the DataNode has more than 1500 file-descriptors opened:</p><p><pre>[{\"triggerName\": \"sample-trigger\",\n  \"triggerExpression\": \"IF (SELECT fd_open WHERE roleName=$ROLENAME and last(fd_open) > 1500) DO health:bad\",\n  \"streamThreshold\": 0, \"enabled\": \"true\"}]</pre></p><p>See the trigger rules documentation for more details on how to write triggers using tsquery.</p><p>The JSON format is evolving and may change in the future and, as a result, backward compatibility is not guaranteed between releases at this time.</p>",
      "relatedName" : "",
      "validationState" : "OK"
    }, {
      "name" : "queue.byte.size",
      "required" : false,
      "default" : "100000000",
      "displayName" : "Queue Size",
      "description" : "Maximum bytes that can be buffered between producer and consumer.",
      "relatedName" : "queue.byte.size",
      "validationState" : "OK"
    }, {
      "name" : "num.producers",
      "required" : false,
      "default" : "1",
      "displayName" : "Number of Producers",
      "description" : "Number of producer instances.",
      "relatedName" : "num.producers",
      "validationState" : "OK"
    }, {
      "name" : "process_swap_memory_thresholds",
      "required" : false,
      "default" : "{\"critical\":\"never\",\"warning\":\"any\"}",
      "displayName" : "Process Swap Memory Thresholds",
      "description" : "The health test thresholds on the swap memory usage of the process.",
      "relatedName" : "",
      "validationState" : "OK"
    }, {
      "name" : "blacklist",
      "required" : false,
      "default" : "",
      "displayName" : "Topic Blacklist",
      "description" : "Regular expression that represent a set of topics to avoid mirroring. Note that whitelist and blacklist parameters are mutually exclusive. If both are defined, only the whilelist is used.",
      "relatedName" : "blacklist",
      "validationState" : "OK"
    }, {
      "name" : "max_log_backup_index",
      "required" : false,
      "default" : "10",
      "displayName" : "Kafka MirrorMaker Maximum Log File Backups",
      "description" : "The maximum number of rolled log files to keep for Kafka MirrorMaker logs.  Typically used by log4j or logback.",
      "relatedName" : "",
      "validationState" : "OK"
    }, {
      "name" : "unexpected_exits_window",
      "required" : false,
      "default" : "5",
      "displayName" : "Unexpected Exits Monitoring Period",
      "description" : "The period to review when computing unexpected exits.",
      "relatedName" : "",
      "validationState" : "OK"
    }, {
      "name" : "queue.size",
      "required" : false,
      "default" : "10000",
      "displayName" : "Message Queue Size",
      "description" : "Number of messages that are buffered between producer and consumer.",
      "relatedName" : "queue.size",
      "validationState" : "OK"
    } ]
  } ],
  "items" : [ {
    "name" : "zookeeper_service",
    "value" : "zookeeper",
    "required" : true,
    "displayName" : "ZooKeeper Service",
    "description" : "Name of the ZooKeeper service that this Kafka service instance depends on",
    "relatedName" : "",
    "validationState" : "OK"
  }, {
    "name" : "service_triggers",
    "required" : false,
    "default" : "[]",
    "displayName" : "Service Triggers",
    "description" : "<p>The configured triggers for this service. This is a JSON formatted list of triggers. These triggers are evaluated as part as the health system. Every trigger expression is parsed, and if the trigger condition is met, the list of actions provided in the trigger expression is executed.</p><p>Each trigger has all of the following fields:</p><ul><li><code>triggerName</code> <strong>(mandatory)</strong> - The name of the trigger. This value must be unique for the specific service. </li><li><code>triggerExpression</code> <strong>(mandatory)</strong> - A tsquery expression representing the trigger. </li><li><code>streamThreshold</code> <strong>(optional)</strong> - The maximum number of streams that can satisfy a condition of a trigger before the condition fires. By default set to 0, and any stream returned causes the condition to fire. </li><li><code>enabled</code> <strong> (optional)</strong> - By default set to 'true'. If set to 'false', the trigger will not be evaluated.</li><li><code>expressionEditorConfig</code> <strong> (optional)</strong> - Metadata for the trigger editor. If present, the trigger should only be edited from the Edit Trigger page; editing the trigger here may lead to inconsistencies.</li></ul></p><p>For example, the followig JSON formatted trigger fires if there are more than 10 DataNodes with more than 500 file-descriptors opened:</p><p><pre>[{\"triggerName\": \"sample-trigger\",\n  \"triggerExpression\": \"IF (SELECT fd_open WHERE roleType = DataNode and last(fd_open) > 500) DO health:bad\",\n  \"streamThreshold\": 10, \"enabled\": \"true\"}]</pre></p><p>See the trigger rules documentation for more details on how to write triggers using tsquery.</p><p>The JSON format is evolving and may change in the future and, as a result, backward compatibility is not guaranteed between releases at this time.</p>",
    "relatedName" : "",
    "validationState" : "OK"
  }, {
    "name" : "KAFKA_service_env_safety_valve",
    "required" : false,
    "displayName" : "Kafka Service Environment Advanced Configuration Snippet (Safety Valve)",
    "description" : "For advanced use only, key-value pairs (one on each line) to be inserted into a role's environment. Applies to configurations of all roles in this service except client configuration.",
    "relatedName" : "",
    "validationState" : "OK"
  }, {
    "name" : "auto.create.topics.enable",
    "required" : false,
    "default" : "true",
    "displayName" : "Topic Auto Creation",
    "description" : "Enable auto creation of topic on the server. If this is set to true then attempts to produce, consume, or fetch metadata for a non-existent topic will automatically create it with the default replication factor and number of partitions.",
    "relatedName" : "auto.create.topics.enable",
    "validationState" : "OK"
  }, {
    "name" : "replica.fetch.max.bytes",
    "required" : false,
    "default" : "1048576",
    "displayName" : "Replica Fetch Size",
    "description" : "The number of byes of messages to attempt to fetch for each partition in the fetch requests the replicas send to the leader.",
    "relatedName" : "replica.fetch.max.bytes",
    "validationState" : "OK"
  }, {
    "name" : "min.insync.replicas",
    "required" : false,
    "default" : "1",
    "displayName" : "Minimum Number of Replicas in ISR",
    "description" : "Define the minimum number of replicas in ISR needed to satisfy a produce request with required.acks=-1 (or all).",
    "relatedName" : "min.insync.replicas",
    "validationState" : "OK"
  }, {
    "name" : "smon_derived_configs_safety_valve",
    "required" : false,
    "displayName" : "Service Monitor Derived Configs Advanced Configuration Snippet (Safety Valve)",
    "description" : "For advanced use only, a list of derived configuration properties that will be used by the Service Monitor instead of the default ones.",
    "relatedName" : "",
    "validationState" : "OK"
  }, {
    "name" : "kafka.metrics.reporters",
    "required" : false,
    "default" : "nl.techop.kafka.KafkaHttpMetricsReporter",
    "displayName" : "List of Metric Reporters",
    "description" : "Comma-separated list of class names of metric reporters. HTTP reporter is included by default.",
    "relatedName" : "kafka.metrics.reporters",
    "validationState" : "OK"
  }, {
    "name" : "default.replication.factor",
    "required" : false,
    "default" : "1",
    "displayName" : "Replication Factor",
    "description" : "The default replication factor for automatically created topics.",
    "relatedName" : "default.replication.factor",
    "validationState" : "OK"
  }, {
    "name" : "process_username",
    "required" : false,
    "default" : "kafka",
    "displayName" : "System User",
    "description" : "The user that this service's processes should run as.",
    "relatedName" : "",
    "validationState" : "OK"
  }, {
    "name" : "num.partitions",
    "required" : false,
    "default" : "1",
    "displayName" : "Default Number of Partitions",
    "description" : "The default number of partitions per topic.",
    "relatedName" : "num.partitions",
    "validationState" : "OK"
  }, {
    "name" : "zookeeper.session.timeout.ms",
    "required" : false,
    "default" : "6000",
    "displayName" : "Zookeeper Session Timeout",
    "description" : "Zookeeper session timeout. If the consumer fails to heartbeat to zookeeper for this period of time it is considered dead and a rebalance will occur.",
    "relatedName" : "zookeeper.session.timeout.ms",
    "validationState" : "OK"
  }, {
    "name" : "monitoring.enabled",
    "required" : false,
    "default" : "true",
    "displayName" : "Enable Kafka Monitoring (Note: Requires Kafka-1.3.0 parcel or higher)",
    "description" : "Enable Kafka monitoring? (Note: Requires Kafka-1.3.0 parcel or higher).",
    "relatedName" : "monitoring.enabled",
    "validationState" : "OK"
  }, {
    "name" : "auto.leader.rebalance.enable",
    "required" : false,
    "default" : "true",
    "displayName" : "Enable Automatic Leader Rebalancing",
    "description" : "If this is enabled the controller will automatically try to balance leadership for partitions among the brokers by periodically returning leadership to the preferred replica for each partition if it is available.",
    "relatedName" : "auto.leader.rebalance.enable",
    "validationState" : "OK"
  }, {
    "name" : "enable_config_alerts",
    "required" : false,
    "default" : "false",
    "displayName" : "Enable Configuration Change Alerts",
    "description" : "When set, Cloudera Manager will send alerts when this entity's configuration changes.",
    "relatedName" : "",
    "validationState" : "OK"
  }, {
    "name" : "delete.topic.enable",
    "required" : false,
    "default" : "true",
    "displayName" : "Enables Delete Topic",
    "description" : "When delete topic is disabled, deleting topics through the admin tools has no effect.",
    "relatedName" : "delete.topic.enable",
    "validationState" : "OK"
  }, {
    "name" : "replica.lag.max.messages",
    "required" : false,
    "default" : "4000",
    "displayName" : "Allowed Replica Lag",
    "description" : "If a replica falls more than this many messages behind the leader, the leader will remove the follower from ISR and treat it as dead.",
    "relatedName" : "replica.lag.max.messages",
    "validationState" : "OK"
  }, {
    "name" : "controlled.shutdown.enable",
    "required" : false,
    "default" : "true",
    "displayName" : "Controlled Shutdown",
    "description" : "Enable controlled shutdown of the broker. If enabled, the broker will move all leaders on it to some other brokers before shutting itself down. This reduces the unavailability window during shutdown.",
    "relatedName" : "controlled.shutdown.enable",
    "validationState" : "OK"
  }, {
    "name" : "unclean.leader.election.enable",
    "required" : false,
    "default" : "false",
    "displayName" : "Enable Unclean Leader Election",
    "description" : "Enable replicas not in the ISR set to be elected as leader as a last resort, even though doing so may result in data loss.",
    "relatedName" : "unclean.leader.election.enable",
    "validationState" : "OK"
  }, {
    "name" : "enable_alerts",
    "required" : false,
    "default" : "true",
    "displayName" : "Enable Service Level Health Alerts",
    "description" : "When set, Cloudera Manager will send alerts when the health of this service reaches the threshold specified by the EventServer setting eventserver_health_events_alert_threshold",
    "relatedName" : "",
    "validationState" : "OK"
  }, {
    "name" : "message.max.bytes",
    "required" : false,
    "default" : "1000000",
    "displayName" : "Maximal Message Size",
    "description" : "The maximum size of a message that the server can receive. It is important that this property be in sync with the maximum fetch size the consumers use or else an unruly producer will be able to publish messages too large for consumers to consume.",
    "relatedName" : "message.max.bytes",
    "validationState" : "OK"
  }, {
    "name" : "zookeeper.chroot",
    "required" : false,
    "default" : "",
    "displayName" : "Zookeeper Root",
    "description" : "ZNode in zookeeper that should be used as a root for this Kafka cluster.",
    "relatedName" : "zookeeper.chroot",
    "validationState" : "OK"
  }, {
    "name" : "process_groupname",
    "required" : false,
    "default" : "kafka",
    "displayName" : "System Group",
    "description" : "The group that this service's processes should run as.",
    "relatedName" : "",
    "validationState" : "OK"
  } ]
}
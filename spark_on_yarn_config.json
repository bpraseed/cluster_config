{
  "roleTypeConfigs" : [ {
    "roleType" : "GATEWAY",
    "items" : [ {
      "name" : "spark_history_enabled",
      "required" : false,
      "default" : "true",
      "displayName" : "Enable History",
      "description" : "Write Spark application history logs to HDFS.",
      "relatedName" : "spark.eventLog.enabled",
      "validationState" : "OK"
    }, {
      "name" : "enable_config_alerts",
      "required" : false,
      "default" : "false",
      "displayName" : "Enable Configuration Change Alerts",
      "description" : "When set, Cloudera Manager will send alerts when this entity's configuration changes.",
      "relatedName" : "",
      "validationState" : "OK"
    }, {
      "name" : "spark-conf/spark-defaults.conf_client_config_safety_valve",
      "required" : false,
      "displayName" : "Spark Client Advanced Configuration Snippet (Safety Valve) for spark-conf/spark-defaults.conf",
      "description" : "For advanced use only, a string to be inserted into the client configuration for <strong>spark-conf/spark-defaults.conf</strong>.",
      "relatedName" : "",
      "validationState" : "OK"
    }, {
      "name" : "client_config_priority",
      "required" : false,
      "default" : "51",
      "displayName" : "Alternatives Priority",
      "description" : "The priority level that the client configuration will have in the Alternatives system on the hosts. Higher priority levels will cause Alternatives to prefer this configuration over any others.",
      "relatedName" : "",
      "validationState" : "OK"
    }, {
      "name" : "client_config_root_dir",
      "required" : false,
      "default" : "/etc/spark",
      "displayName" : "Deploy Directory",
      "description" : "The directory where the client configs will be deployed",
      "relatedName" : "",
      "validationState" : "OK"
    }, {
      "name" : "spark_data_serializer",
      "required" : false,
      "default" : "org.apache.spark.serializer.KryoSerializer",
      "displayName" : "Spark Data Serializer",
      "description" : "Name of class implementing org.apache.spark.serializer.Serializer to use in Spark applications.",
      "relatedName" : "spark.serializer",
      "validationState" : "OK"
    }, {
      "name" : "spark_deploy_mode",
      "required" : false,
      "default" : "client",
      "displayName" : "Default Application Deploy Mode",
      "description" : "Which deploy mode to use by default. Can be overridden by users when launching applications.",
      "relatedName" : "spark_deploy_mode",
      "validationState" : "OK"
    }, {
      "name" : "spark-conf/log4j.properties_client_config_safety_valve",
      "required" : false,
      "displayName" : "Spark Client Advanced Configuration Snippet (Safety Valve) for spark-conf/log4j.properties",
      "description" : "For advanced use only, a string to be inserted into the client configuration for <strong>spark-conf/log4j.properties</strong>.",
      "relatedName" : "",
      "validationState" : "OK"
    }, {
      "name" : "spark-conf/spark-env.sh_client_config_safety_valve",
      "required" : false,
      "displayName" : "Spark Client Advanced Configuration Snippet (Safety Valve) for spark-conf/spark-env.sh",
      "description" : "For advanced use only, a string to be inserted into the client configuration for <strong>spark-conf/spark-env.sh</strong>.",
      "relatedName" : "",
      "validationState" : "OK"
    }, {
      "name" : "spark_shuffle_service_enabled",
      "required" : false,
      "default" : "false",
      "displayName" : "Enable Shuffle Service",
      "description" : "Enable Usage of External Shuffle Service.  The External Shuffle Service is not robust to NodeManager restarts and so is not recommended for production use.",
      "relatedName" : "spark.shuffle.service.enabled",
      "validationState" : "OK"
    } ]
  }, {
    "roleType" : "SPARK_YARN_HISTORY_SERVER",
    "items" : [ {
      "name" : "history_server_max_heapsize",
      "value" : "67108864",
      "required" : false,
      "default" : "268435456",
      "displayName" : "Java Heap Size of History Server in Bytes",
      "description" : "Maximum size for the Java process heap memory. Passed to Java -Xmx. Measured in bytes.",
      "relatedName" : "history_server_max_heapsize",
      "validationState" : "OK"
    }, {
      "name" : "spark_yarn_history_server_scm_health_enabled",
      "required" : false,
      "default" : "true",
      "displayName" : "History Server Process Health Test",
      "description" : "Enables the health test that the History Server's process state is consistent with the role configuration",
      "relatedName" : "",
      "validationState" : "OK"
    }, {
      "name" : "spark_yarn_history_server_fd_thresholds",
      "required" : false,
      "default" : "{\"critical\":\"70.0\",\"warning\":\"50.0\"}",
      "displayName" : "File Descriptor Monitoring Thresholds",
      "description" : "The health test thresholds of the number of file descriptors used. Specified as a percentage of file descriptor limit.",
      "relatedName" : "",
      "validationState" : "OK"
    }, {
      "name" : "log_dir",
      "required" : false,
      "default" : "/var/log/spark",
      "displayName" : "History Server Log Directory",
      "description" : "The log directory for log files of the role History Server.",
      "relatedName" : "log_dir",
      "validationState" : "OK"
    }, {
      "name" : "rm_io_weight",
      "required" : false,
      "default" : "500",
      "displayName" : "Cgroup I/O Weight",
      "description" : "Weight for the read I/O requests issued by this role. The greater the weight, the higher the priority of the requests when the host experiences I/O contention. Must be between 100 and 1000. Defaults to 1000 for processes not managed by Cloudera Manager.",
      "relatedName" : "blkio.weight",
      "validationState" : "OK"
    }, {
      "name" : "log_threshold",
      "required" : false,
      "default" : "INFO",
      "displayName" : "History Server Logging Threshold",
      "description" : "The minimum log level for History Server logs",
      "relatedName" : "",
      "validationState" : "OK"
    }, {
      "name" : "rlimit_fds",
      "required" : false,
      "displayName" : "Maximum Process File Descriptors",
      "description" : "If configured, overrides the process soft and hard rlimits (also called ulimits) for file descriptors to the configured value.",
      "relatedName" : "",
      "validationState" : "OK"
    }, {
      "name" : "log4j_safety_valve",
      "required" : false,
      "displayName" : "History Server Logging Advanced Configuration Snippet (Safety Valve)",
      "description" : "For advanced use only, a string to be inserted into <strong>log4j.properties</strong> for this role only.",
      "relatedName" : "",
      "validationState" : "OK"
    }, {
      "name" : "max_log_size",
      "required" : false,
      "default" : "200",
      "displayName" : "History Server Max Log Size",
      "description" : "The maximum size, in megabytes, per log file for History Server logs.  Typically used by log4j or logback.",
      "relatedName" : "",
      "validationState" : "OK"
    }, {
      "name" : "unexpected_exits_thresholds",
      "required" : false,
      "default" : "{\"critical\":\"any\",\"warning\":\"never\"}",
      "displayName" : "Unexpected Exits Thresholds",
      "description" : "The health test thresholds for unexpected exits encountered within a recent period specified by the unexpected_exits_window configuration for the role.",
      "relatedName" : "",
      "validationState" : "OK"
    }, {
      "name" : "enable_config_alerts",
      "required" : false,
      "default" : "false",
      "displayName" : "Enable Configuration Change Alerts",
      "description" : "When set, Cloudera Manager will send alerts when this entity's configuration changes.",
      "relatedName" : "",
      "validationState" : "OK"
    }, {
      "name" : "history_server_web_port",
      "required" : false,
      "default" : "18088",
      "displayName" : "History Server WebUI Port",
      "description" : "The port of the history server WebUI",
      "relatedName" : "history.port",
      "validationState" : "OK"
    }, {
      "name" : "SPARK_YARN_HISTORY_SERVER_role_env_safety_valve",
      "required" : false,
      "displayName" : "History Server Environment Advanced Configuration Snippet (Safety Valve)",
      "description" : "For advanced use only, key-value pairs (one on each line) to be inserted into a role's environment. Applies to configurations of this role except client configuration.",
      "relatedName" : "",
      "validationState" : "OK"
    }, {
      "name" : "role_triggers",
      "required" : false,
      "default" : "[]",
      "displayName" : "Role Triggers",
      "description" : "<p>The configured triggers for this role. This is a JSON formatted list of triggers. These triggers are evaluated as part as the health system. Every trigger expression is parsed, and if the trigger condition is met, the list of actions provided in the trigger expression is executed.</p><p>Each trigger has all of the following fields:</p><ul><li><code>triggerName</code> <strong>(mandatory)</strong> - The name of the trigger. This value must be unique for the specific role. </li><li><code>triggerExpression</code> <strong>(mandatory)</strong> - A tsquery expression representing the trigger. </li><li><code>streamThreshold</code> <strong>(optional)</strong> - The maximum number of streams that can satisfy a condition of a trigger before the condition fires. By default set to 0, and any stream returned causes the condition to fire. </li><li><code>enabled</code> <strong> (optional)</strong> - By default set to 'true'. If set to 'false', the trigger will not be evaluated.</li><li><code>expressionEditorConfig</code> <strong> (optional)</strong> - Metadata for the trigger editor. If present, the trigger should only be edited from the Edit Trigger page; editing the trigger here may lead to inconsistencies.</li></ul></p><p>For example, the following JSON formatted trigger configured for a DataNode fires if the DataNode has more than 1500 file-descriptors opened:</p><p><pre>[{\"triggerName\": \"sample-trigger\",\n  \"triggerExpression\": \"IF (SELECT fd_open WHERE roleName=$ROLENAME and last(fd_open) > 1500) DO health:bad\",\n  \"streamThreshold\": 0, \"enabled\": \"true\"}]</pre></p><p>See the trigger rules documentation for more details on how to write triggers using tsquery.</p><p>The JSON format is evolving and may change in the future and, as a result, backward compatibility is not guaranteed between releases at this time.</p>",
      "relatedName" : "",
      "validationState" : "OK"
    }, {
      "name" : "process_swap_memory_thresholds",
      "required" : false,
      "default" : "{\"critical\":\"never\",\"warning\":\"any\"}",
      "displayName" : "Process Swap Memory Thresholds",
      "description" : "The health test thresholds on the swap memory usage of the process.",
      "relatedName" : "",
      "validationState" : "OK"
    }, {
      "name" : "spark_yarn_history_server_host_health_enabled",
      "required" : false,
      "default" : "true",
      "displayName" : "History Server Host Health Test",
      "description" : "When computing the overall History Server health, consider the host's health.",
      "relatedName" : "",
      "validationState" : "OK"
    }, {
      "name" : "enable_alerts",
      "required" : false,
      "default" : "true",
      "displayName" : "Enable Health Alerts for this Role",
      "description" : "When set, Cloudera Manager will send alerts when the health of this role reaches the threshold specified by the EventServer setting eventserver_health_events_alert_threshold",
      "relatedName" : "",
      "validationState" : "OK"
    }, {
      "name" : "max_log_backup_index",
      "required" : false,
      "default" : "10",
      "displayName" : "History Server Maximum Log File Backups",
      "description" : "The maximum number of rolled log files to keep for History Server logs.  Typically used by log4j or logback.",
      "relatedName" : "",
      "validationState" : "OK"
    }, {
      "name" : "rm_memory_hard_limit",
      "required" : false,
      "default" : "-1",
      "displayName" : "Cgroup Memory Hard Limit",
      "description" : "Hard memory limit to assign to this role, enforced by the Linux kernel. When the limit is reached, the kernel will reclaim pages charged to the process. If reclaiming fails, the kernel may kill the process. Both anonymous as well as page cache pages contribute to the limit. Use a value of -1 B to specify no limit. By default processes not managed by Cloudera Manager will have no limit.",
      "relatedName" : "memory.limit_in_bytes",
      "validationState" : "OK"
    }, {
      "name" : "config/spark-env.sh_role_safety_valve",
      "required" : false,
      "displayName" : "History Server Advanced Configuration Snippet (Safety Valve) for config/spark-env.sh",
      "description" : "For advanced use only, a string to be inserted into <strong>config/spark-env.sh</strong> for this role only.",
      "relatedName" : "",
      "validationState" : "OK"
    }, {
      "name" : "rm_memory_soft_limit",
      "required" : false,
      "default" : "-1",
      "displayName" : "Cgroup Memory Soft Limit",
      "description" : "Soft memory limit to assign to this role, enforced by the Linux kernel. When the limit is reached, the kernel will reclaim pages charged to the process if and only if the host is facing memory pressure. If reclaiming fails, the kernel may kill the process. Both anonymous as well as page cache pages contribute to the limit. Use a value of -1 B to specify no limit. By default processes not managed by Cloudera Manager will have no limit.",
      "relatedName" : "memory.soft_limit_in_bytes",
      "validationState" : "OK"
    }, {
      "name" : "unexpected_exits_window",
      "required" : false,
      "default" : "5",
      "displayName" : "Unexpected Exits Monitoring Period",
      "description" : "The period to review when computing unexpected exits.",
      "relatedName" : "",
      "validationState" : "OK"
    }, {
      "name" : "process_auto_restart",
      "required" : false,
      "default" : "false",
      "displayName" : "Automatically Restart Process",
      "description" : "When set, this role's process is automatically (and transparently) restarted in the event of an unexpected failure.",
      "relatedName" : "",
      "validationState" : "OK"
    }, {
      "name" : "rm_cpu_shares",
      "required" : false,
      "default" : "1024",
      "displayName" : "Cgroup CPU Shares",
      "description" : "Number of CPU shares to assign to this role. The greater the number of shares, the larger the share of the host's CPUs that will be given to this role when the host experiences CPU contention. Must be between 2 and 262144. Defaults to 1024 for processes not managed by Cloudera Manager.",
      "relatedName" : "cpu.shares",
      "validationState" : "OK"
    } ]
  } ],
  "items" : [ {
    "name" : "yarn_service",
    "value" : "yarn",
    "required" : true,
    "displayName" : "YARN (MR2 Included) Service",
    "description" : "Name of the YARN (MR2 Included) service that this Spark service instance depends on",
    "relatedName" : "",
    "validationState" : "OK"
  }, {
    "name" : "service_triggers",
    "required" : false,
    "default" : "[]",
    "displayName" : "Service Triggers",
    "description" : "<p>The configured triggers for this service. This is a JSON formatted list of triggers. These triggers are evaluated as part as the health system. Every trigger expression is parsed, and if the trigger condition is met, the list of actions provided in the trigger expression is executed.</p><p>Each trigger has all of the following fields:</p><ul><li><code>triggerName</code> <strong>(mandatory)</strong> - The name of the trigger. This value must be unique for the specific service. </li><li><code>triggerExpression</code> <strong>(mandatory)</strong> - A tsquery expression representing the trigger. </li><li><code>streamThreshold</code> <strong>(optional)</strong> - The maximum number of streams that can satisfy a condition of a trigger before the condition fires. By default set to 0, and any stream returned causes the condition to fire. </li><li><code>enabled</code> <strong> (optional)</strong> - By default set to 'true'. If set to 'false', the trigger will not be evaluated.</li><li><code>expressionEditorConfig</code> <strong> (optional)</strong> - Metadata for the trigger editor. If present, the trigger should only be edited from the Edit Trigger page; editing the trigger here may lead to inconsistencies.</li></ul></p><p>For example, the followig JSON formatted trigger fires if there are more than 10 DataNodes with more than 500 file-descriptors opened:</p><p><pre>[{\"triggerName\": \"sample-trigger\",\n  \"triggerExpression\": \"IF (SELECT fd_open WHERE roleType = DataNode and last(fd_open) > 500) DO health:bad\",\n  \"streamThreshold\": 10, \"enabled\": \"true\"}]</pre></p><p>See the trigger rules documentation for more details on how to write triggers using tsquery.</p><p>The JSON format is evolving and may change in the future and, as a result, backward compatibility is not guaranteed between releases at this time.</p>",
    "relatedName" : "",
    "validationState" : "OK"
  }, {
    "name" : "enable_config_alerts",
    "required" : false,
    "default" : "false",
    "displayName" : "Enable Configuration Change Alerts",
    "description" : "When set, Cloudera Manager will send alerts when this entity's configuration changes.",
    "relatedName" : "",
    "validationState" : "OK"
  }, {
    "name" : "spark_jar_hdfs_path",
    "required" : false,
    "default" : "",
    "displayName" : "Spark Jar Location (HDFS)",
    "description" : "The location of the Spark jar in HDFS. If left blank, CM will use the Spark jar installed on the cluster nodes.",
    "relatedName" : "spark_jar_hdfs_path",
    "validationState" : "OK"
  }, {
    "name" : "kerberos_princ_name",
    "required" : false,
    "default" : "spark",
    "displayName" : "Kerberos Principal",
    "description" : "Kerberos principal short name used by all roles of this service.",
    "relatedName" : "",
    "validationState" : "OK"
  }, {
    "name" : "spark_authenticate",
    "required" : false,
    "default" : "false",
    "displayName" : "Spark Authentication",
    "description" : "Enable whether the Spark communication protocols do authentication using a shared secret.",
    "relatedName" : "spark.authenticate",
    "validationState" : "OK"
  }, {
    "name" : "spark_shuffle_service_port",
    "required" : false,
    "default" : "7337",
    "displayName" : "Spark Shuffle Service Port",
    "description" : "The port the Spark Shuffle Service listens for fetch requests.",
    "relatedName" : "spark.shuffle.service.port",
    "validationState" : "OK"
  }, {
    "name" : "spark_history_log_dir",
    "required" : false,
    "default" : "/user/spark/applicationHistory",
    "displayName" : "Spark History Location (HDFS)",
    "description" : "The location of Spark application history logs in HDFS. Changing this value will not move existing logs to the new location.",
    "relatedName" : "spark.eventLog.dir",
    "validationState" : "OK"
  }, {
    "name" : "enable_alerts",
    "required" : false,
    "default" : "true",
    "displayName" : "Enable Service Level Health Alerts",
    "description" : "When set, Cloudera Manager will send alerts when the health of this service reaches the threshold specified by the EventServer setting eventserver_health_events_alert_threshold",
    "relatedName" : "",
    "validationState" : "OK"
  }, {
    "name" : "SPARK_ON_YARN_service_env_safety_valve",
    "required" : false,
    "displayName" : "Spark Service Environment Advanced Configuration Snippet (Safety Valve)",
    "description" : "For advanced use only, key-value pairs (one on each line) to be inserted into a role's environment. Applies to configurations of all roles in this service except client configuration.",
    "relatedName" : "",
    "validationState" : "OK"
  }, {
    "name" : "smon_derived_configs_safety_valve",
    "required" : false,
    "displayName" : "Service Monitor Derived Configs Advanced Configuration Snippet (Safety Valve)",
    "description" : "For advanced use only, a list of derived configuration properties that will be used by the Service Monitor instead of the default ones.",
    "relatedName" : "",
    "validationState" : "OK"
  }, {
    "name" : "process_groupname",
    "required" : false,
    "default" : "spark",
    "displayName" : "System Group",
    "description" : "The group that this service's processes should run as.",
    "relatedName" : "",
    "validationState" : "OK"
  }, {
    "name" : "process_username",
    "required" : false,
    "default" : "spark",
    "displayName" : "System User",
    "description" : "The user that this service's processes should run as.",
    "relatedName" : "",
    "validationState" : "OK"
  } ]
}